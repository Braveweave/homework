## 计算机科学的基本定义

通过几周的专业导论课，我对计算机科学这门学科有了更加全面、深刻的了解。


计算机科学是研究 **信息** 和 **计算** 的理论基础，以及它们在计算机系统上实现和
应用的实践技术。这说明了计算机科学的研究内容十分广泛，包括了计算机的设计、制造
和应用（即利用计算机进行信息获取、表示、存储、处理、控制等工作）的理论、方法以
及技术。


而什么是这门学科的核心研究问题呢？我们知道，计算机最早研发出来是用作计算导弹轨
道，减少大量人工计算操作的。其实这就告诉了我们计算机的两个最重要的用途：(1) 计
算；(2) 自动化处理。因此我们可以毫不犹豫的看到计算机科学研究的核心问题就是：
“如何 **自动化** 处理问题，以及什么样的问题不能被 **自动化**。”


另一方面，虽然计算机科学研究领域十分广阔，但是通过课程学习，我们也不难将这些前
沿研究划分为以下几个重要问题：

* 计算机原理

* 算法

* 数据结构

* 程序、程序语言以及程序设计方法论

* 软件

下面简单地介绍一下这几个核心问题。


### 计算机原理

计算机是这门学科所有研究对象的载体，通过研究这一部件的构成原理，可以解决许多基
础问题以及取得新的突破。


### 算法

算法是计算机学科的灵魂。算法是指一系列的解决问题的操作步骤。通过对算法的研究，
能使我们更加深刻地了解到问题的本质以及发掘到可能的求解方法。

算法具有以下的定义：

- 非形式化定义
- 有穷性
- 确定性
- 0 或多个输入
- 1 或多个输出
- 可行性


### 数据结构

如果说算法是灵魂，那么数据结构就是程序设计中的骨架。通过数据结构这一定性模型，
我们可以对客观、复杂的现实问题进行抽象化处理，简化问题的复杂度以及令问题更加
清晰具体。


而一个数据结构由三个部分组成：数据的逻辑结构、存储结构和运算。


### 程序、程序语言以及程序设计方法论

程序就是我们使用计算机进行解决问题的一系列的指令，代表了解决方法的步骤。正如
Nikiklaus Wirth 说的那样：

> 程序 = 算法 + 数据结构

一个程序是建立在算法和数据结构上的。那么程序设计其实就是指通过一系列的算法（解
决方案）对数据结构（问题的本体）进行“加工”，最终解决这个问题。而在这一个过程中
，就包含了许多不同的方法论、语言工具和计算环境。


### 软件

软件一般是指计算机系统中的程序及其文档。对软件的研究对象有：开发、维护方法；
程序本身涉及的理论和技术。


-----------

## 我对计算机学科体系的理解


通过上面的一系列分析不难看出，计算机科学是一门研究 **信息** 和 **计算方法** 的
科学，通过大量使用数学、物理等相关学科以及学科内的理论，对实际问题、信息进行
处理；同时为我们提供了 **自动化处理** 一系列具有相同特点问题的理论依据以及可行
方案。


而计算机科学研究对象可以概括为以下几部分：

* 计算理论 (theory of computation)
* 算法与数据结构 (algorithms and data structures)
* 编程方法与编程语言 (programming methodology and languages)
* 计算机元素和架构 (computer elements and architecutre)


同时，计算机科学还有以下两点不同于其他学科的特点：

1. **抽象性** 通过隐藏细节等技巧来将具体问题形式化，降低问题的复杂度（排除与解
决问题的无关因素），从而只需清楚问题的定义以及方案即可用已有的知识解决。

2. **一般性** 对一系列原子操作进行定义后，通过复用和组合来解决问题。


总的来说，可以用以下三个词来概括计算机科学这门学科：


**工程** 计算机科学是一门实际意义很强的学科。计算机学科通过虚拟的建模技术，将
现实世界的以一些条件归约(constraint)起来，从而得到更加简洁、通用的解决方案。


**科学** 计算机科学是一门严谨的科学。计算机科学是基于大量的数学、物理理论而建立
起来的；程序设计的过程也体现了人类的抽象推导过程。另外一个方面，计算机的发展也
对其他学科产生了许多重要的影响（例如定理自动化证明）。


**艺术** 虽然计算机真正意义上的发展历史还不足百年，但是在这段充满激情和奇迹的
历史中，逐步发展出许多不同的文化（黑客文化、开源文化等）。同时像词法、修辞、
逻辑、算术等人类特有的艺术文化，在计算机相关领域中（例如编程语言、递归）也有体
现出来，因此不难看出计算机科学其实也是人类思维活动的一个艺术产物。


--------------

## 专业学习要点


### 知识点

作为一个计算机科学专业的学生，在本科4年的学习中，有以下一些知识点需要掌握：

- 基础学科：

    * 高等数学
    * 离散数学
    * 线性代数
    * 英语

- 专业学科：

    * 程序设计
    * 算法与算法分析
    * 计算机组织及体系结构
    * 操作系统
    * 人机交互原理
    * 图形学、可视化计算
    * 人工智能
    * 信息理论
    * 数值计算

### 需要的能力

#### 抽象

将具体问题抽象化，是计算机科学一切“魔法”的源泉。现实的工程问题通常要对
复杂的问题进行建模，而这往往会带来很高的复杂度。而在计算机科学中，对于一个问题
，通常先要除去一些无关因素，将问题化归到已知领域中的某一类型问题。例如，处理像
肯德基这样的餐厅的排队最优问题（即怎样的队列才能使候餐时间最短），我们要先把眼光
放到有关这个问题的几个要素上：人流量、队列数量、平均等候速度、最小等候速度。通
过一系列的抽象，不难看出这其实是一个**优先队列**的问题；然后我们通过建立这一数
据结构，模拟这一行为（不一定要用模拟的方法），并找出最优算法；最后结合实际情况
来进行验证。从这个例子不难发现，抽象地处理问题有利于我们找到问题的本质。


#### 已知问题的一般化

对已知问题一般化就是使将已经知道的问题进行推广、同化，然后用来解决另一些具有相同
特点的问题。以这样的一个描述为例：

> 在两种可能里选择一个

我们可以将这个**操作**一般化成 if 操作（即选择结构），然后，当我们处理另外一个
**包含**有**选择**的问题时，就可以将 if 当作一个**可复用**的模块来完成操作。


#### 递归

计算机科学是一门研究**自动化处理问题**的学科，而**自动化处理**的一种重要的完成
方式就是**循环**。循环通常有两种：


1. 连续重复的同样的操作，例如录入一个年级学生的成绩。

2. 解决一个可分解的问题，而每个分解出来的子问题都和母问题具有相似性。


对于第二种问题，我们大脑很难，也不必去将处理整个问题的所有细节、具体步骤考虑进来，
只需要设立一套简单的对绝大部分子问题都适用的规则来进行求解，然后再把这些子问题
的解组合起来，就得到原问题的解。


以快速排序为例，将一个无序的列表按一定顺序排列起来就是排序问题要解决的“大”问题；
而这个“大”问题的一个小一点的子问题就是：以某一个值为基准，分别将列表中比这个值
小的元素和比这个值大的元素的两个子列表进行排序，最后将这三部分合并起来就可以得
到一个完整的按某种顺序排列的列表。


从上面的描述中，我们不难按照递归的一般步骤分离出几个关键操作：

* 以某一个值为基准 …… 两个子列表 （分割问题）
* 两个子列表都含有未排序的元素 （子问题和母问题相似）
* 对子列表进行排序 （套用相同的规则）
* 将三部分合并 （子问题的解组合起来）


综上可以看出递归思考这一能力将会给我们解决问题带来极大的便利。


------------

## 对专业内相关学科的看法


下面简单的对计算机科学中的网络和数据库两个子领域进行描述。


### 网络

网络自从20世纪60年代问世以来就注定会对人类社会产生巨大的影响。经过几十年的发展
，如今网络已经渗入到我们生活的每一个角落。现代化的网络建立在 TCP/IP 这一协议上
，因此很大一部分对网络的应用、研究都应该回归到协议本身。


而更贴近生活应用部分的互联网，更是具有巨大的潜力。信息（广义的信息，如一则新闻）
通过互联网以前所未有的速度向外扩散，通过对这些信息的发掘、处理、分析可以获得很多
有趣的结果，例如会有人尝试使用一些社交工具来预测选情[1]（尽管不一定可行），但这
从侧面反应出互联网具有反应群体心理状态的潜力。


另一方面互联网因为其便捷也使人类社会进入了前所未有的“信息爆炸”时代，每天都会产
生巨大的新的信息。那么要怎么处理这些庞大的数据呢？显然以传统的技术手段难以解决
这个问题，因此对“大数据”(big data)的研究也应时代要求产生。


总的来说，网络正在以前所未有的速度在进化，在使用网络的过程中，会催生出许多有趣
的、对人类社会带来很大影响的研究问题；同时由于人类对网络的日益依赖，对网络的研
究显得十分重要。



### 数据库

数据库作为数据的集合载体，早在20世纪70年代就投入应用。而早期的数据库更关注的是
如何高效地处理各种操作，也因此产生了许多不同类型的数据库，例如关系型、文档型、
对象型。随着摩尔定律一次又一次的迭代，计算机效率已经足够快，而数据库的性能也得
到了极大的提升；因此我们应该把研究重心转移到数据库本身用途上，即怎样才能高效地
表示、处理一系列数据呢？


当下最流行的数据库当数关系型的数据库，在一般的关系型数据库中，数据都以二维的形
式存储；当要进行大量跨表查询时就有可能导致效率降低，而且在读取完数据后，一般都
还需要进行组合，重新构造模型(ORM)。通常这样的操作都会导致一定程度上的浪费，因此
随着对关系型数据库、文档型数据库的研究不断深入，以后很大可能可以把一个完整的对
像存进数据库里，而不用通过拆分、重新组合的操作。


--------------

## 计算机科学发展前景


下面以**量子计算机为例**简单地谈谈计算机科学的发展前景以及热门领域


### 量子计算机

我们知道，像化学、物理这样的学科，有时需要通过模拟一定的量子系统来进行建模、
分析，但是在这个模拟的过程中，时空复杂度均会非常高，因此一般的通用计算机并不能
胜任，所以不禁让人思考，通用计算机是否有其极限？如果有，那么要怎么才能突破这个
极限？


根据现代计算机的结构组成原理可知，其最微小的储存单位是比特(bits)，而一比特通常
只可以表示 0 或 1，因此很大程度上限制了计算机的计算能力，亦即在对于一个具有 2^n 
种可能的系统进行模拟的过程中，普通的计算机一次只能获得其中的一个结果。这很大程度
上限制了通用计算机的性能。


那么我们能不能拿另外一种“元件”来表示数据而获得更加多的状态呢？（即可以同时表示
多种状态，不单单是 0 或 1）在20世纪60年代末，Steve Wiesner 提出了使用**量子**来
完成这个功能，第一次提出了**量子计算机**这一概念。


一般来说，量子计算机是通过维护一系列的**量子比特**(qubits)，以**量子算法**来
进行数据操作，并在得出输出态之后进行一定的测量，而得出计算结果。在量子计算机的
变换过程中，会产生所有可能的正变换，亦即通过一次运算就能获得 2^n 个结果，因此
量子计算机具有更快的计算速度。正是由于这个原因，许多在传统计算机上时间复杂度较
高的算法在量子计算机上可能仅需要多项式时间。（例如大部分的传统加密算法都是基于
大素数分解，因此用普通的手段来破解往往需要可观的时间，但是在量子计算机上，很可
能只需要几秒钟就能解决，因为分解质因数的算法[2]在量子计算机上的速度会快很多。）


由上面的例子可以看出量子计算机具有巨大的潜力（有可能在多项式时间内解决部分 NP
问题）、研究的价值（会使密码学等学科产生巨大变革）和商业意义[3]，是计算机科学
的一个重要的研究热点。


--------------

## 个人发展展望

通过这几个星期的专业导论课的学习，我了解、学习到了当前计算机学科的研究领域以及
热点方向，为今后的本科学习点明了方向，带来了很好的启发。


由以上的分析、介绍不难看出，计算机已经成为了我们日常生活中非常重要的一部分，而
在今后也会变得越来越重要，会对人类社会带来革命性的影响，因此，对计算机进行系统
性的学习，将会给我们带来很大的好处。在另一方面，计算机科学仍处于非常年轻的阶段
，所以只要我们敢想敢做，一定能做出成绩来，创造出有益于社会的成果。


为了更好地学习计算机科学这一门学科，我计划在本科 4 年里掌握以下的知识：


* 高等数学以及其应用

* 程序设计语言、技巧和方法论

* 算法分析与设计

* 数据结构设计与应用

* 计算机组成原理及实现

* 编译原理

* 操作系统

* 人工智能

* 软件开发方法论

* 领域、行业相关知识

同时在这 4 年里，也要多参加各种科研竞赛、活动，将理论知识推广到实践之中，从而提
高自己的水平。


-----------

## Cites

[1] http://www.technologyreview.com/view/427807/twitter-cannot-predict-elections-either/

[2] http://en.wikipedia.org/wiki/Shor%27s_algorithm

[3] http://www.dwavesys.com/en/products-services.html
